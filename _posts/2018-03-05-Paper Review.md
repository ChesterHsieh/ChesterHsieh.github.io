# [Notes on Noise Contrastive Estimation and Negative Sampling](https://arxiv.org/pdf/1410.8251.pdf_)

It's kind of wired to write down note for note. In turn this isn't the typical NLP paper. 

 ## Improvement
 Cost on softmax is huge when training the word2vec model.  That's inherietence problem with multiple class proble. Intuitive requirement for the loss function in multi-class problem is entropy for the probability. 

***Reduce computing cost***
## Method

![Probability for ***context** *c* for ***word*** *w*](https://media.licdn.com/dms/image/C5112AQGTvxJFr-qXLA/article-inline_image-shrink_1000_1488/0?e=1557360000&v=beta&t=wkUHIU5P-LPHks6tGQ8sx_zqX5Xuuwi7EymCIBuuc-w)
How to map this problem to the binary classification problem
=> Naive Bayes classifier
We generate Î¸ to simulate real distribution. 
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTY2MDE1OTk0LDY4MDIyMDYwM119
-->