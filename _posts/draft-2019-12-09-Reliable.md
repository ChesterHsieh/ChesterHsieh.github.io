# adversarial attackin real life
adding noise on original image
CNN to sensitive to leaner X 
Not to fit the actual feature
# Example
## adversarial attack
Bounding box detector
+奇怪圖片 fail 
## Stop sign 
加入奇怪 noise to Stop sign
speed limit/ case by case, we can't decide waht to learn
## Security
Attack face ID, reverse to black box
-----------

如何生成奇怪的 data, 創造出robust的DL的問題..
# 4 types
- 猜model weight, gradient based attack. 
- iterative fast gradient sign
- score basd attack
  改變圖片中一個pixel, 就會完全改變結果. 
- New model 

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE4NDMzMTY1NzRdfQ==
-->