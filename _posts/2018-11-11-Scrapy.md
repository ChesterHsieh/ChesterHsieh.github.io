---
layout:     post
title:      Crawl on the Twitter
subtitle:   Scrapy + python
date:       2018-11-08
author:    Chester
header-img: img/spider.jpg
catalog: true
tags:
    - web crawl
---

# Our target


That's everything in the beginning. To get the data set and prepare them on the server.

Here's one idea I want to try. 

To build a restful API to suggest the Emoji.

Hmm............... It doesn't sounds cool. Since the Coursera course has same idea for model. I will try to go farther. 

However I need to scrape the data first.

# Every Piece we Nedd
1. Stable Scraper
2. AWS for hosting scraper(or any other plat
3. Database


### Stable Scraper
Here's the problem. 

I know there's wonderful and complicated framework for Scraper. => [Scpay]((https://scrapy.org/))
I think we might not need this time for such a simple purpose.



## Scrapy
Why **Scrapy**? Not just** beautiful soup **?



[Scrapy offical web](https://scrapy.org/)

[Not limited scraper](https://github.com/kennethreitz/twitter-scraper)


# Rule creator
There's another way to setting the spider rule. We can use GUI tool to assist us to scrap the information. 

Take the information I want to use 

# Deployment
**TODO** 



<!--stackedit_data:
eyJoaXN0b3J5IjpbMTkzNTg4MDExNCw5MDMwODE2NzMsLTM4Mj
c0MDk1NiwtMjA4NzQwNzg4MSwtMzgyNzQwOTU2XX0=
-->